{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e83decf-71f9-48e5-bffc-17d548c2e0de",
   "metadata": {},
   "source": [
    "# Klasifikace obrázků CIFAR-10 pomocí konvoluční sítě"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750c076e-79f8-48ae-8088-461d9c224911",
   "metadata": {},
   "source": [
    "Úkolem cvičení je natrénovat konvoluční síť pro klasifikaci na datasetu CIFAR-10 s alespoň 75% úpěšností na validační sadě."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6697cab3-e8b3-4cce-9003-6f497ab446e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a8abaa-f64f-4380-9828-10260ea778a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "sys.path.append('..')  # import tests\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import ans\n",
    "from tests import test_convolutional_network\n",
    "from tests.test_neural_library import randn_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813cac1a-eb5d-4301-806f-ac399d2d4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(profile='short')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5737310a-d782-441d-bf52-b7b19294c3a4",
   "metadata": {},
   "source": [
    "# Dvourozměrná konvoluce jako diferencovatelná funkce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ac7c06-b8e3-4842-b1e0-0c1fc8e8050f",
   "metadata": {},
   "source": [
    "Konvoluci nejprve naimplementujeme jako diferencovatelnou operaci odvozenou od třídy `ans.funcitonal.Function`.\n",
    "\n",
    "**Dopředný průchod**\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    z_{n,f,u,v} & = \\sum_{c=1}^{C}\\sum_{i=1}^{K}\\sum_{j=1}^{K}{ w_{f,c,i,j} \\cdot x_{n, c, D \\cdot i + S \\cdot u, D \\cdot j + S \\cdot v} + b_f } \\\\\n",
    "    % \\forall (f, u, v) & \\in \\{1, ..., F\\} \\times \\{1, ..., Q\\} \\times \\{1, ..., Q\\} \\\\\n",
    "    % Q & = \\lfloor \\frac{M + 2 \\cdot P - K}{S} \\rfloor + 1\n",
    "\\end{split}\n",
    "$$\n",
    "- $x_{n,c,i,j}$ je jeden prvek tensoru vstupu $\\boldsymbol{x} = [x_{n,c,i,j}]$ s rozměry $N \\times C \\times M \\times M$\n",
    "- $N$ je velikost dávky, tj. počet \"obrázků\" ve vstupním tensoru $\\boldsymbol{x}$\n",
    "- $M$ je výška a šířka tensoru vstupu $\\boldsymbol{x}$; pro jednoduchost předpokládáme čtvercový vstup, tj. např. $224 \\times 224$\n",
    "- $C$ je počet kanálů tensoru vstupu $\\boldsymbol{x}$; např. pro RGB je $C = 3$\n",
    "- $w_{f,c,i,j}$ je jeden prvek váhového tensoru $\\boldsymbol{w} = [w_{f,c,i,j}]$ o rozměrech $F \\times C \\times K \\times K$\n",
    "- $K$ je velikost konvolučního filtru; pro jednoduchost předpokládáme čtvercový tvar, např. $3 \\times 3$\n",
    "- $F$ je celkový počet konvolučních filtrů\n",
    "- $b_f$ je jeden prvek vektoru biasů $\\boldsymbol{b} = [b_1, \\ldots, b_F]$ o rozměru $F$; vychází tedy jeden bias (skalár) na každý z $F$ filtrů\n",
    "- $z_{n,f,u,v}$ je jeden prvek výstupního tensoru $\\boldsymbol{z} = [z_{n,f,u,v}]$ s rozměry $N \\times F \\times Q \\times Q$\n",
    "\n",
    "Pro rozměr výstupu $Q$ platí\n",
    "$$\n",
    "Q = \\left\\lfloor \\frac{M + 2 \\cdot P - K}{S} \\right\\rfloor + 1\n",
    "$$\n",
    "- $S$ je *hyperparametr* a značí krok (stride)\n",
    "- $P$ je *hyperparametr* a značí, o kolik nul je nutné nastavit vstup v prostorových dimenzích (padding)\n",
    "- $D$ je *hyperparametr* a značí dilataci (dilation)\n",
    "\n",
    "Vstup je nastaven o nulové hodnoty, tzn. že platí\n",
    "$$\n",
    "x_{n, c, i \\lt 1, j \\lt 1} = x_{n, c, i \\gt M, j \\gt M} = 0\n",
    "$$\n",
    "\n",
    "Celou operaci konvoluce, kdy se vztah $z_{n,f,u,v} = \\ldots$ vyhodnotí pro všechny $(f,u,v)$ (všechny prvky tensoru $\\boldsymbol{z}_n$), zkráceně zapíšeme jako\n",
    "$$\n",
    "\\boldsymbol{z}_n = \\textrm{conv2}\\left( \\boldsymbol{x}_n, \\boldsymbol{w}, \\boldsymbol{b}; S, P, D \\right)\n",
    "$$\n",
    "- $\\boldsymbol{x}_n$ je $n$-tý \"obrázek\" dávky jako tensor s rozměry $C \\times M \\times M$\n",
    "- $\\boldsymbol{z}_n$ je $n$-tý výstup dávky jako tensor s rozměry $F \\times Q \\times Q$\n",
    "\n",
    "**Zpětný průchod**\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\overline{x}_{n,c,i,j} & = \\sum_{f=1}^{F}\\sum_{u=1}^{Q}\\sum_{v=1}^{Q}{ \\overline{z}_{n,f,u,v} \\cdot w_{f, c, D \\cdot i - S \\cdot u, D \\cdot j - S \\cdot v} } \\\\\n",
    "    \\overline{w}_{f,c,i,j} & = \\sum_{n=1}^N\\sum_{u=1}^{Q}\\sum_{v=1}^{Q}{ \\overline{z}_{n,f,u,v} \\cdot x_{n, c, D \\cdot i + S \\cdot u, D \\cdot j + S \\cdot v} } \\\\\n",
    "    \\overline{b}_f & = \\sum_{n=1}^N\\sum_{u=1}^{Q}\\sum_{v=1}^{Q}{ \\overline{z}_{n,f,u,v} }\n",
    "\\end{split}\n",
    "$$\n",
    "- $\\overline{\\boldsymbol{z}}_n$ je příchozí gradient na výstup $\\boldsymbol{z}_n$ jako tensor s rozměry $F \\times Q \\times Q$\n",
    "\n",
    "Zkráceně lze zapsat zpětný průchod jako\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\overline{\\boldsymbol{x}}_n & = \\textrm{conv2}^\\top(\\overline{\\boldsymbol{z}}_n, \\boldsymbol{w}, \\boldsymbol{0}; S, P, D) \\\\\n",
    "    \\boldsymbol{\\overline{w}}_{f,c} & = \\sum_{n=1}^N{ \\textrm{conv2}(\\boldsymbol{x}_{n,c}, \\overline{\\boldsymbol{z}}_{n,f}, \\boldsymbol{0}; D, P, S) }\n",
    "\\end{split}\n",
    "$$\n",
    "- $\\textrm{conv2}^\\top(\\cdot)$ je tzv. transponovaná dvourozměrná konvoluce\n",
    "- $\\boldsymbol{x}_{n,c}$ je $c$-tý kanál $n$-tého vstupu jako matice s rozměry $M \\times M$\n",
    "- $\\overline{\\boldsymbol{z}}_{n,f}$ je příchozí gradient na $f$-tý kanál $n$-tého výstupu jako tensor s rozměry $Q \\times Q$\n",
    "- $\\boldsymbol{\\overline{w}}_{f,c}$ je vypočítáný gradient na $c$-tý kanál $f$-tého filtru jako matice s rozměry $K \\times K$\n",
    "\n",
    "**Implementace**\n",
    "\n",
    "Vzhledem ke složitosti a výpočetní náročnosti nebudeme funkce $\\textrm{conv2}(\\cdot)$ a $\\textrm{conv2}^\\top(\\cdot)$ implementovat vlastními silami pomocí for cyklů ani komplikovaného broadcastingu, ale použijeme funkce `conv2d`, resp. `conv_transpose2d` modulu `torch.nn.functional` knihovny Pytorch. Není to vyžadováno, ale gradient na váhy $\\boldsymbol{\\overline{w}}$ lze získat i zcela bez použití cyklů.\n",
    "\n",
    "*Output padding u `conv_transpose2d` pro výpočet gradientu na vstup:* \n",
    "\n",
    "- Pokud je stride $S \\gt 1$, může se stát, že z různě velkých vstupů $\\boldsymbol{x}_n$, $\\boldsymbol{x}_m$ funkcí vzniknou stejně velké výstupy $\\boldsymbol{z}_n$, resp. $\\boldsymbol{z}_m$. Pokud potom použijeme $\\textrm{conv2}^\\top$ jako zpětný průchod pro výpočet gradientu na vstup $\\overline{\\boldsymbol{x}}_n$, není rozměr výsledného gradientu na vstup jednoznačně určená, a tak $\\overline{\\boldsymbol{x}}_n$ nemusí svou velikostí přesně odpovídat $\\boldsymbol{x}$. Funkce `torch.nn.conv_transpose2d` proto zavádí argument `output_padding`, který výstup nastaví o požadovanou hodnotu. Aby měl $\\overline{\\boldsymbol{x}}_n$ rozměry shodné s $\\boldsymbol{x}_n$ a procházely všechny testy, je nutné `output_padding` dopočítat jako\n",
    "$$\n",
    "% (Q - 1) \\cdot S - 2 \\cdot P + D \\cdot (K - 1) + O + 1 = M \\\\\n",
    "O = M - (Q - 1) \\cdot S + 2 \\cdot P - (K - 1) \\cdot D - 1\n",
    "$$\n",
    "- a to *v obou dimenzích*, tj. pro výšku i šířku.\n",
    "\n",
    "*Oříznutí gradientu na váhy:*\n",
    "\n",
    "- U gradientu na váhy je situace o něco jednodušší. Může se stát, že výstup konvoluce $\\boldsymbol{\\overline{w}}_{f,c} = \\textrm{conv2}(\\boldsymbol{x}_{n,c}, \\overline{\\boldsymbol{z}}_{n,f}, \\ldots)$ vyjde větší než $K \\times K$. V takovém případě stačí výsledek o přebytečné hodnoty \"zdola\" a \"zprava\" oříznout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff01f9-3d0d-48d6-adaf-ec7ec73be56b",
   "metadata": {},
   "source": [
    "### TODO: implementujte funkci `ans.functional.Conv2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9167b6d9-545b-49dc-b7bd-b8b564fa6174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with various params\n",
    "ans.autograd.gradcheck(\n",
    "    ans.functional.Conv2d.apply,\n",
    "    (\n",
    "        randn_var(7, 2, 5, 9, name='input'),\n",
    "        randn_var(4, 2, 3, 3, name='weight'),\n",
    "        randn_var(4, name='bias')\n",
    "    ),\n",
    "    params=dict()\n",
    "    # params=dict(stride=2)\n",
    "    # params=dict(stride=2, padding=1, dilation=2)\n",
    "    # params=dict(stride=2, padding=1, groups=2)  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7565f7-1f5d-4a43-9984-283508a056d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_backward can take a while due to slow numeric_gradient\n",
    "test_convolutional_network.TestConv2dFunction.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0655f-7de7-4e70-a561-d2f3fcca1878",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dvourozměrná konvoluce jako vrstva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc7562-d0d5-4630-b42a-fed470b30fc4",
   "metadata": {},
   "source": [
    "Podobně jako všechny ostatní diferencovatelné operace i dvourozměrnou konvoluci vytvoříme i jako vrstvu typu `ans.modules.Module`. Vrstva `Conv2d` by měla:\n",
    "- uchovávat v sobě a v metodě `__init__` automaticky vhodně inicializovat parametry $\\boldsymbol{w}$ a $\\boldsymbol{b}$, tedy váhy a bias konvoluce\n",
    "- v dopředném průchodu `forward` vypočítat výstup jako $\\boldsymbol{z}_n = \\textrm{conv2}\\left( \\boldsymbol{x}_n, \\boldsymbol{w}, \\boldsymbol{b}; S, P, D \\right)$ (viz výše)\n",
    "\n",
    "**Inicializace vah**\n",
    "\n",
    "- Inicializovat váhy budeme podobně jako u lineární vrstvy, tj. jednou z variant metody Xavier, tak, [jak je tomu v knihovně v PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html). Prvky váhového tensoru $\\boldsymbol{w} = [w_{fcij}]$ s rozměry $F \\times C \\times K \\times K$ navzorkujeme z rovnoměrného náhodného rozdělení\n",
    "$$\n",
    "w_{fcij} \\sim \\mathcal{U}\\left(\\frac{-1}{\\sqrt{CK^2}}, \\frac{+1}{\\sqrt{CK^2}}\\right)\n",
    "$$\n",
    "- Použijeme k tomu metodu [`torch.rand`](https://pytorch.org/docs/stable/generated/torch.rand.html). Výsledný váhový tensor musí být atribut typu `Variable`.\n",
    "\n",
    "**Inicializace biasu**\n",
    "\n",
    "- Bias bude nepovinný parametr a příp. jej inicializujeme na nuly metodou [`torch.zeros`](https://pytorch.org/docs/stable/generated/torch.zeros.html). Výsledný vektor musí být atribut typu `Variable`, příp. objekt `None`, pokud je do `__init__` předáno `bias=False`.\n",
    "\n",
    "**Dopředný průchod**\n",
    "- Dopředný průchod `Conv2d.forward` by měl volat `ans.functional.Conv2d.apply`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda2b00-b8c2-47c4-9751-442a40c5e32b",
   "metadata": {},
   "source": [
    "### TODO: implementujte vrstvu `ans.modules.Conv2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convolutional_network.TestConv2dModule.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3dff28-ab4e-42b1-9aec-ce458a8f8bc4",
   "metadata": {},
   "source": [
    "## Rectified Linear Unit (ReLU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6fa22b-920b-47a0-87ce-8ba8c0b0838e",
   "metadata": {},
   "source": [
    "Sigmoid nelinearita nemá příliš vhodné vlastnosti pro zpětnou propagaci a u hlubokých konvolučních sítí může poměrně významně snižovat potenciální úspěšnost modelu. Efektivnější se z tohoto pohledu se ukázala rektifikovaná lineární jednotka, tzv. ReLU., bez které se na rozdíl od [multilayer-perceptron](multilayer-perceptron.ipynb) tentokrát již neobejdeme.\n",
    "\n",
    "**Dopředný průchod**\n",
    "\n",
    "$$\n",
    "z = \\begin{cases}\n",
    "    0 & \\textrm{pokud} & x \\le 0 \\\\\n",
    "    x & \\textrm{pokud} & x \\gt 0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "- $x$ je reálné číslo (skalár)\n",
    "- $z$ je reálně číslo (skalár)\n",
    "\n",
    "**Zpětný průchod**\n",
    "\n",
    "$$\n",
    "\\overline{x} = \\begin{cases}\n",
    "    0 & \\textrm{pokud} & x \\le 0 \\\\\n",
    "    \\overline{z} & \\textrm{pokud} & x \\gt 0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "- $\\overline{z}$ je příchozí gradient na $z$\n",
    "\n",
    "**Dávkové zpracování**\n",
    "\n",
    "Operaci ReLU aplikujeme na všechny prvky vstupu nezávisle na sobě.\n",
    "\n",
    "**Poznámka**\n",
    "\n",
    "Jelikož operace ReLU není diferencovatelná, numerický gradient se pro malé hodnoty $x \\approx 0$ kolem bodu zlomu v nule nechová jako subgradient a nevychází \"správně\". Pokud vám `gradcheck` v testu selže i přes podle vás správnou implementaci zpětného průchodu, zkuste ho opakovat. Pravděpodobnost selhávajícího testu je cca 27 %."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d2818-9a5e-42a0-854b-a14f3bceed42",
   "metadata": {},
   "source": [
    "### TODO: implementujte funkci `ans.functional.ReLU` a vrstvu `ans.modules.ReLU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d305a5f4-8a76-408a-8774-fd1e666505f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.autograd.gradcheck(\n",
    "    ans.functional.ReLU.apply,\n",
    "    (\n",
    "        randn_var(8, 4, std=10., name='input'),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f771b38-9fe2-42f5-ba68-0698c62278a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convolutional_network.TestReLU.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269ccac4-79ff-4b00-93fd-a7551a05c258",
   "metadata": {},
   "source": [
    "# Max-pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3998724c",
   "metadata": {},
   "source": [
    "Téměř nedílnou součástí konvolučních sítí jsou tzv. [pooling vrstvy](https://d2l.ai/chapter_convolutional-neural-networks/pooling.html). Implementujeme si jednu z nejčastějších, tzv. max-pooling.\n",
    "\n",
    "**Dopředný průchod**\n",
    "\n",
    "$$\n",
    "z_{n,c,u,v} = \\max_{i=1,\\ldots,K}\\max_{j=1,\\ldots,K}{x_{n,c,K \\cdot (u-1)+i,K \\cdot (v-1)+j}}\n",
    "$$\n",
    "- $x_{n,c,k,l}$ je jeden prvek tensoru vstupu $\\boldsymbol{x} = [x_{n,c,k,l}]$ s rozměry $N \\times C \\times M \\times M$\n",
    "- $N$ je velikost dávky, tj. počet \"obrázků\" ve vstupním tensoru $\\boldsymbol{x}$\n",
    "- $M$ je výška a šířka tensoru vstupu $\\boldsymbol{x}$; pro jednoduchost předpokládáme čtvercový vstup, tj. např. $224 \\times 224$\n",
    "- $C$ je počet kanálů tensoru vstupu $\\boldsymbol{x}$; např. pro RGB je $C = 3$\n",
    "- $K$ je velikost okolí pro pooling; pro jednoduchost předpokládáme čtvercový tvar, např. $2 \\times 2$\n",
    "- $z_{n,c,u,v}$ je jeden prvek výstupního tensoru $\\boldsymbol{z} = [z_{n,c,u,v}]$ s rozměry $N \\times C \\times Q \\times Q$\n",
    "- indexování prvků začíná jedničkou\n",
    "\n",
    "Abychom replikovali chování `MaxPool2d` knihovny, pro velikost výstupu bude platit\n",
    "$$\n",
    "Q = \\left\\lfloor\\frac{M}{K}\\right\\rfloor\n",
    "$$\n",
    "To znamená, že v případech, kdy velikost vstupu $M$ není dělitelná velikostí okna $K$, nadbytečné hodnoty ve vstupu $\\boldsymbol{x}$ budeme ignorovat.\n",
    "\n",
    "**Zpětný průchod**\n",
    "$$\n",
    "% \\overline{x}_{n,c,Ku+k,Kv+l} = \\begin{cases}\n",
    "%     \\overline{z}_{n,c,u,v} & \\textrm{pokud} & x_{n,c,Ku+k,Kv+l} = \\max_{i=1,\\ldots,K}\\max_{j=1,\\ldots,K}{x_{n,c,Ku+i,Kv+j}} \\\\\n",
    "%     0 & \\textrm{jinak}\n",
    "% \\end{cases}\n",
    "\\overline{x}_{n,c,k,l} = \\begin{cases}\n",
    "    \\overline{z}_{n,c,u,v} & \\textrm{pokud} & x_{n,c,k,l} = \\max_{i=1,\\ldots,K}\\max_{j=1,\\ldots,K}{x_{n,c,K\\cdot u+i,K\\cdot v+j}} \\\\\n",
    "    0 & \\textrm{jinak}\n",
    "\\end{cases}\n",
    "$$\n",
    "- $u = \\lfloor \\frac{k-1}{K} \\rfloor$, $v = \\lfloor\\frac{l-1}{K}\\rfloor$\n",
    "- $\\overline{\\boldsymbol{z}} = [\\overline{z}_{n,c,u,v}]$ je příchozí gradient na výstup $\\boldsymbol{z}$ jako tensor s rozměry $N \\times C \\times Q \\times Q$\n",
    "- $\\overline{x}_{n,c,k,l}$ je jeden prvek (skalár) gradientu na vstup $\\overline{\\boldsymbol{x}}$\n",
    "- celkový gradient na vstup $\\overline{\\boldsymbol{x}}$ je tensor s rozměry $N \\times C \\times M \\times M$\n",
    "\n",
    "Všechny prvky vstupu $\\boldsymbol{x}$, které v dopředném průchodu vykázaly maximální hodnotu ve svém lokálním okolí o velikosti $K \\times K$, mají gradient roven příchozímu gradientu na odpovídající pozici. Ostatní prvky vstupu $\\boldsymbol{x}$ mají gradient nulový.\n",
    "\n",
    "**Implementace**\n",
    "\n",
    "Oproti možnostem v knihovně PyTorch si redukujeme počet hyperparametrů a ponecháme pouze velikost pooling okolí $K$ pod jménem `window_size` (v PyTorch se parametr nazývá `kernel_size`). Tento parametr bude celé číslo, tzn. že se omezíme na čtvercové okno o roměru $K \\times K$.\n",
    "\n",
    "*Operaci naprogramujte vektorově bez použití cyklů!*\n",
    "- Např. max-pooling vektoru s velikostí okna `window_size=2`:\n",
    "``` python\n",
    ">>> x = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    ">>> values, indices = x.reshape(3, 2).max(dim=1)\n",
    "(tensor([2, 4, 5]), tensor([1, 0, 0]))\n",
    "```\n",
    "- U dvourozměrného vstupu je potřeba obdobný reshape provést pro výšku i šířku.\n",
    "- Hodit se může také funkce `torch.transpose`, pomocí které lze posunout přidané dimenze na poslední dvě místa, což umožní reshape na `(..., window_size * window_size)`.\n",
    "\n",
    "**Max-pooling jako vrstva**\n",
    "\n",
    "Vrstva `MaxPool2d` v metodě `__init__` převezme velikost pooling okna $K$ jako parametr `window_size` a v dopředném průchodu pouze zavolá `ans.functional.MaxPool2d.apply`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ec58b-bae0-443a-9495-effe30c6a23a",
   "metadata": {},
   "source": [
    "### TODO: implementujte funkci `ans.functional.MaxPool2d` a vrstvu `ans.modules.MaxPool2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f24318-45a3-4729-923e-f6d7603d0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.autograd.gradcheck(\n",
    "    ans.functional.MaxPool2d.apply,\n",
    "    (\n",
    "        randn_var(5, 3, 4, 7, name='input'),\n",
    "    ),\n",
    "    params=dict(window_size=3),\n",
    "    eps=1e-4  # minimize risk of fail\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d5876c-f2f3-428c-ba85-19dd3f72198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convolutional_network.TestMaxPool2dFunction.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785ffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convolutional_network.TestMaxPool2dModule.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbc5871-b7ca-4d3b-a22c-c52d31fecd02",
   "metadata": {},
   "source": [
    "# Operace `Variable.reshape`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db960d19",
   "metadata": {},
   "source": [
    "Poslední operací potřebnou pro konvoluční sítě je reshape $N \\times F \\times M \\times M$-rozměrného výstupu konvoluce do rozměrů $N \\times D$, kde\n",
    "- $N$ je počet vstupů v dávce\n",
    "- $D = F \\cdot M^2$ je dimenze příznaků.\n",
    "\n",
    "Takto přetvarovaná data můžeme snadno klasifikovat pomocí lineární vrstvy `Linear` např. do 10 tříd tak, abychom v každém řádku získali 10 klasifikačních skóre (logitů) podobně jako ve cvičeních [`linear-classification`](linear-classification.ipynb) a [`multilayer-perceptron`](multilayer-perceptron.ipynb). Operaci si zadefinujeme jako obecné přetvarování tensoru.\n",
    "\n",
    "**Dopředný průchod**\n",
    "\n",
    "$$\n",
    "% \\begin{split}\n",
    "\\boldsymbol{z} = \\textrm{reshape}(\\boldsymbol{x}; F_1, \\ldots, F_Z) \\\\\n",
    "% \\textrm{tak, aby} \\; F_1 \\cdot \\ldots \\cdot F_Z = D_1 \\cdot \\ldots \\cdot D_X\n",
    "% \\end{split}\n",
    "$$\n",
    "- $\\boldsymbol{x}$ je vstupní tensor o libovolných rozměrech $D_1 \\times \\ldots \\times D_X$\n",
    "- $\\boldsymbol{z}$ je výstupní tensor o rozměru $F_1 \\times \\ldots \\times F_Z$\n",
    "\n",
    "Pokud $\\prod_{i=1}^{F_Z}F_i \\ne \\prod_{i=1}^{D_X}D_i$ (nesedí počet prvků), funkce vyhodí výjimku typu `RuntimeError`.\n",
    "\n",
    "**Zpětný průchod**\n",
    "\n",
    "$$\n",
    "\\overline{\\boldsymbol{x}} = \\textrm{reshape}(\\overline{\\boldsymbol{z}}; D_1, \\ldots, D_X)\n",
    "$$\n",
    "- $\\overline{\\boldsymbol{z}}$ je příchozí gradient na výstup jako tensor o rozměrech $F_1 \\times \\ldots \\times F_Z$\n",
    "- $\\overline{\\boldsymbol{x}}$ je výsledný gradient na vstupní tensor $\\boldsymbol{x}$ o rozměrech $D_1 \\times \\ldots \\times D_X$\n",
    "\n",
    "**Implementace**\n",
    "\n",
    "Místo odvozování z typu `ans.functional.Function` si vzhledem k její jednoduchosti operaci implementujeme přímo ve třídě `Variable` metodou `reshape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4f3349",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.autograd.gradcheck(\n",
    "    lambda var: var.reshape(5, 3 * 4, 7),\n",
    "    # lambda var: var.reshape(5, 3, 4 * 7),\n",
    "    (\n",
    "        randn_var(5, 3, 4, 7, name='input'),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1599fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convolutional_network.TestReshape.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715d2c79",
   "metadata": {},
   "source": [
    "# Vrstva `Flatten`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cb85d9",
   "metadata": {},
   "source": [
    "Po vzoru PyTorch si rovněž zadefinujeme vrstvu `Flatten`, což nám umožní jednoduše vkládat tuto operaci např. do `Sequential`. Operace provede\n",
    "$$\n",
    "\\boldsymbol{z} = \\textrm{reshape}(\\boldsymbol{x}; N, D)\n",
    "$$\n",
    "- $\\boldsymbol{x}$ je vstupní tensor o rozměrech $N \\times D_2 \\times \\ldots \\times D_X$\n",
    "- $\\boldsymbol{z}$ je výstupní tensor o rozměrech $N \\times D$, kde $D = \\prod_{i=2}^{D_X}D_i$\n",
    "\n",
    "\n",
    "\n",
    "**Inicializace**\n",
    "\n",
    "- Vrstva nebude definovat metodu `__init__` a tudíž bude cela bez parametrů.\n",
    "\n",
    "**Dopředný průchod**\n",
    "\n",
    "- Dopředný průchod bude volat metodu `Variable.reshape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc4e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convolutional_network.TestFlattenModule.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ba9329",
   "metadata": {},
   "source": [
    "# Model konvoluční sítě VGG7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ebbd85",
   "metadata": {},
   "source": [
    "Nyní máme zadefinovány operace související s dvourozměrnou konvolucí jako funkční bloky a zbývá nám navrhnout celkový mode sítě. Můžeme přitom využít všechny ostatní operace z minulých úloh jako např. lineární vrstvu. Jelikož hledání ideální konvoluční architektury metodou pokus omyl by mohlo být časově náročné, budeme implementovat jednu konkrétní architekturu odvozenou z [VGG](https://arxiv.org/abs/1409.1556). Síť bude vypadat následovně:\n",
    "\n",
    "`CR(64), M(2), CR(128), M(2), CR(256), M(2), CR(512), M(2), CR(512), M(2), LR(512), L(10)`\n",
    "\n",
    "kde:\n",
    "- např. `CR(64)` znamená dvourozměrnou konvoluci (`C`) se 64 filtry a biasy následovanou ReLU (`R`); všechny konvoluce mají velikost 3x3\n",
    "- `M(2)` znamená max-pooling s oknem o velikosti 2 a krokem 2\n",
    "- `LR(512)` znamená lineární vrstvu (`L`) následovanou ReLU (`R`) s *výstupním* vektorem o rozměru 512\n",
    "\n",
    "Konvoluční síť po vzoru článku od Simonyan & Zisserman pojmenujeme jako VGG7, protože má 7 vrstev s trénovatelnými parametry. Model zadefinujeme jako třídu `VGG7` odvozenou z `ans.modules.Module`. Třída `VGG7` by měla:\n",
    "- v `__init__` zadefinovat potřebné operace jako své atributy typu `ans.modules.Module`\n",
    "- ve `forward` zavolat své vrstvy ve správném pořadí na vstup typu `ans.autograd.Variable`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bfa14e",
   "metadata": {},
   "source": [
    "### TODO: Implementuje model konvoluční sítě VGG7 jako třídu `VGG7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d30aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG7(ans.modules.Module):\n",
    "\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        ########################################\n",
    "        # TODO: implement\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "        # ENDTODO\n",
    "        ########################################\n",
    "    \n",
    "    # feel free to add auxiliary methods here\n",
    "    # def my_function(...)\n",
    "    \n",
    "    def forward(self, x: ans.autograd.Variable) -> ans.autograd.Variable:\n",
    "        ########################################\n",
    "        # TODO: implement\n",
    "\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        # ENDTODO\n",
    "        ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476d97a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convolutional_network.TestVGG7.eval(model_cls=VGG7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a945e8-23b5-4a9e-ab2c-c2a84050d556",
   "metadata": {},
   "source": [
    "# Načtení dat a příprava dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6befc-be48-4b12-8946-8bc3b31a0956",
   "metadata": {},
   "source": [
    "Oproti minulým cvičením trochu pozměníme práci s daty a namísto `ans.data.BatchLoader` využijeme `torch.utils.data.DataLoader`. Vynecháme rovněž vlastní implementaci funkce `preprocess` a uvolníme tak prostor pro využití již hotových transformací z modulu `torchvision.transforms`. To vše nám později umožní jednoduše augmentovat data pro zvýšení klasifikační úspěšnosti.\n",
    "\n",
    "Preprocessing lze přidat přidat přímo do objektu `CIFAR10` argumentem `transform`, kterým typicky bývá sekvence typu `torchvision.transforms.Compose`. Třída `Compose` převezme `list` operací, které při zavolání na vstup jednu po druhé aplikuje. Děje se tak přitom automaticky v objektu datasetu `CIFAR10` vždy předtím, než daný obrázek vrátí jako vzorek.\n",
    "\n",
    "Předáme pro začátek pouze dvě operace, kterými bude každý obrázek modifikován:\n",
    "1. `torchvision.transforms.ToTensor()` převede obrázek z `numpy.ndarray` se `shape=(H, W, C)` a `dtype=numpy.uint8` (rozsah 0..255) na `torch.Tensor` se `shape=(C, H, W)` a `dtype=torch.float32` (rozsah 0..1),\n",
    "2. `torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))` odečte od každé trojice RGB hodnot (pixelu) vektor `(0.485, 0.456, 0.406)` a vydělí `(0.229, 0.224, 0.225)`. Hodnoty jsou vypočtené jako očekávaná hodnota a standardní odchylka RGB pixelů na datasetu ImageNet a zajišťují, že vstupní tensory do sítě mají přibližně nulový průměr a jednotkový rozptyl v RGB. Shodná čísla používají veškeré předtrénované modely v modulu `torchvision.models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823e97c7-f2ff-4ca0-860e-b4682b27d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root = '../data',\n",
    "    train = True,\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ]),\n",
    "    download = True\n",
    ")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4a34c-a139-42cc-b698-983fad73356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = torchvision.datasets.CIFAR10(\n",
    "    root = '../data',\n",
    "    train = False,\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ]),\n",
    "    download = True\n",
    ")\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d011ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_dataset[0]\n",
    "x.shape, x.dtype, x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d430d2-4fbd-4054-8131-a00e3ae295b8",
   "metadata": {},
   "source": [
    "# Funkce pro trénování"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de24e0f-f2ab-4ae0-84d3-56f4fbc5be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(scores: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        scores: output linear scores (logits before softmax); shape (num_samples, num_classes)\n",
    "        targets: vector of class indicies (integers); shape (num_samples,)\n",
    "    Returns:\n",
    "        acc: averare accuracy on the batch; tensor containing single number (scalar), e.g. \"tensor(0.364)\"\n",
    "    \"\"\"\n",
    "    \n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8938965c-3f00-44ae-aca1-0113d3715983",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convolutional_network.TestAccuracy.eval(accuracy_fn=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f78a86-fb3b-44b9-a4ca-d0c27649c796",
   "metadata": {},
   "source": [
    "Oproti cvičením [linear-classification](linear-classification.ipynb) a [multilayer-perceptron](multilayer-perceptron.ipynb) ve funkcích `train_step` a `val_step` nebudeme provádět `preprocess`, protože jsme jej refaktorovali přímo do datasetu, viz výše. Ostatní kroky zůstavají shodné. Opět nezapomeňte na `zero_grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721760d7-756b-45d1-b058-42bbc81a8c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    model: ans.modules.Module,\n",
    "    criterion: ans.modules.Module,\n",
    "    optimizer: ans.optim.Optimizer,\n",
    ") -> tuple[float, float]:\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return loss.data.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbee1614-7ad4-4a4d-a4ac-3b1cc2f3b916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val_step(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    model: ans.modules.Module,\n",
    "    criterion: ans.modules.Module\n",
    ") -> tuple[float, float]:\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return loss.data.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c9f763-b693-4147-9f9f-0c2bb6d59835",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convolutional_network.TestSteps.eval(train_step_fn=train_step, val_step_fn=val_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec24c8-3435-46af-9e19-a9a6d13aa5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    loader: ans.data.BatchLoader,\n",
    "    model: ans.modules.Module,\n",
    "    criterion: ans.modules.Module\n",
    ") -> tuple[float, float]:\n",
    "    total_loss = 0.\n",
    "    total_acc = 0.\n",
    "    for inputs, targets in loader:\n",
    "        loss, acc = val_step(inputs, targets, model, criterion)\n",
    "        total_loss += loss\n",
    "        total_acc += acc\n",
    "    return total_loss / len(loader), total_acc / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1784ff8d-c80e-4924-84fa-f9711b519a5d",
   "metadata": {},
   "source": [
    "# Hlavní cyklus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d387b2b0",
   "metadata": {},
   "source": [
    "Na rozdíl od minulých cvičení je doporučeno trénovat na GPU, pokud vám je k dispozici. Jinak totiž mohou být konvoluční sítě poměrně pomalé a trénování zdlouhavé. V závislosti na konkrétním modelu a HW prostředcích může hlavní cyklus běhat 10x až cca 25x rychleji na GPU než na CPU. Přesun zajišťuje třída `ans.data.DataLoader`, která je odvozená od `torch.utils.data.DataLoader`.\n",
    "\n",
    "Pár poznámek k trénování:\n",
    "- Adam je tolerantnější a robustnější vůči neoptimálně navrženým hyperparametrům a v takových případech rychleji a lépe konverguje než SGD s momentum.\n",
    "- Není nezbytně nutné mnohahodinové trénování, přestože může pomoci \"vymačkat\" z modelu o několik procent více. K dosažení požadované validační úspešnosti 75 % může s dobře nastavenými hyperparametry (a ideálně s optimizérem Adam) stačit cca 5-6 epoch.\n",
    "- Pro začátek nepoužívejte regularizaci a klidně nechte model se přeučit. Není těžké příliš velkým koeficientem `weight_decay` optimalizaci hlavně na začátku trénování zpomalit až zastavit.\n",
    "- U konvolučních sítí s velkými dávkami (`batch_size`) se může při trénování na GPU vyčerpat VRAM. Pro takové případy je na začátku každé epochy zavolán garbage collector, který se pokusí odstranit z paměti dereferencované objekty, z nichž některé stále mohou držet ukazatele na již nepoužívané tensory a blokovat tak paměť GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547faca1-f80d-4fa4-87d4-d0c9cc6fe30e",
   "metadata": {},
   "source": [
    "### TODO: Natrénujte model VGG7 tak, aby dosáhl alespoň 75% úspěšnosti na validační sadě"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5fbe49-a26a-4990-a4c4-cbad91c1225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# reproducibility\n",
    "ans.utils.seed_everything(0)\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = ...\n",
    "batch_size = ...\n",
    "learning_rate = ...\n",
    "momentum = ...\n",
    "weight_decay = ...\n",
    "device = 'cpu'  # set to 'cuda' to run on the GPU\n",
    "\n",
    "train_loader = ans.data.DataLoader(\n",
    "    train_dataset,\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "val_loader = ans.data.DataLoader(\n",
    "    val_dataset,\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "# init parameters\n",
    "model = VGG7(10)\n",
    "model.to(device=device)\n",
    "\n",
    "# loss function\n",
    "criterion = ans.modules.SoftmaxCrossEntropy()\n",
    "\n",
    "# optimizer\n",
    "optimizer = ...\n",
    "\n",
    "# validate once before training\n",
    "train_loss, train_acc = validate(train_loader, model, criterion)\n",
    "val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "\n",
    "# record history for plotting\n",
    "history = ans.utils.MetricsHistory()\n",
    "history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)\n",
    "\n",
    "# optimize\n",
    "for epoch in range(num_epochs):\n",
    "    gc.collect()\n",
    "    \n",
    "    # train loop\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        loss, acc = train_step(inputs, targets, model, criterion, optimizer)\n",
    "        train_loss = 0.99 * train_loss + 0.01 * loss\n",
    "        train_acc = 0.99 * train_acc + 0.01 * acc\n",
    "    \n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "    \n",
    "    history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143bd46-5535-4deb-957e-2394ddadb8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.best_results('val_acc', 'max'))\n",
    "history.df().plot(secondary_y=['train_acc', 'val_acc']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e22a5b-b18f-4d28-aebd-622416c2fcf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Další vylepšení"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13edebcf-cd06-4343-9987-bac9acaf6e62",
   "metadata": {},
   "source": [
    "Jako bonus můžete podobně jako ve cvičení [multilayer-perceptron](multilayer-perceptron.ipynb) opět zkusit trochu vylepšit skóre sítě. Implementujte postupně následující kroky, opakujte hlavní cyklus znovu a sledujte, zda a jak se mění výsledná přesnost na validační sadě (`val_acc`). Model by měl na konci snažení dosáhnout **alespoň 90% přesnosti** na validační množině."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22916f34-20d4-457b-8386-0d1e4d1b0b39",
   "metadata": {},
   "source": [
    "## Datová augmentace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17162fed",
   "metadata": {},
   "source": [
    "Jedním z problémů silnějších modelů se na jednodušších datasetech jako CIFAR10 může stát přeučení. Nejlepším řešením je v takovém případě nasbírat dodatečná data, což však mnohdy boužel není možné. Jako substituci ale můžeme vyzkoušet tzv. [datovou augmentaci](https://d2l.ai/chapter_computer-vision/image-augmentation.html#image-augmentation), která spočívá v umělém rozšířování datasetu pomocí náhodných transformací omezeného množství dat, která máme k dispozici.\n",
    "\n",
    "**Doporučené augmentace**\n",
    "\n",
    "V případě obrázků můžeme např. náhodně s pravěpodobností 50 % před vstupem do sítě obrázek horizontálně převrátit, jelikož všechny třídy v datasetu CIFAR10 jsou v tomto symetrické. Stejnou operaci bychom samozřejmě nemohli provádět např. pro číslovky datasetu MNIST. Další vhodnou náhodnou transformací pak může být např. náhodný ořez tak, aby se objekty tříd síti prezentovaly různě velké a také ne pouze uprostřed obrázku.\n",
    "\n",
    "**Implementace**\n",
    "\n",
    "Datovou augmentaci aplikujte pouze na trénovací data a to ještě před původním preprocessingem, který musí zůstat pro obě podmnožiny shodný. Použijte k tomu vhodné třídy dostupné v modulu `torchvision.transforms` a přidejte jejich instance na začátek pole `transform`, které vstupuje jako argument do `CIFAR10.__init__`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cb9510",
   "metadata": {},
   "source": [
    "### TODO: přidejte do trénovací množiny libovolnou datovou augmentaci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe75d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_aug = torchvision.datasets.CIFAR10(\n",
    "    root = '../data',\n",
    "    train = True,\n",
    "    transform = ...,  # TODO: add augmentations & transforms here\n",
    "    download = True\n",
    ")\n",
    "train_dataset_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746299a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convolutional_network.TestAugmentation.eval(train_dataset=train_dataset_aug, val_dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5fbe49-a26a-4990-a4c4-cbad91c1225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# reproducibility\n",
    "ans.utils.seed_everything(0)\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = ...\n",
    "batch_size = ...\n",
    "learning_rate = ...\n",
    "momentum = ...\n",
    "weight_decay = ...\n",
    "device = 'cpu'  # set to 'cuda' to run on the GPU\n",
    "\n",
    "train_loader = ans.data.DataLoader(\n",
    "    train_dataset_aug,  # use augmented dataset\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "val_loader = ans.data.DataLoader(\n",
    "    val_dataset,\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "# init parameters\n",
    "model = VGG7(10)\n",
    "model.to(device=device)\n",
    "\n",
    "# loss function\n",
    "criterion = ans.modules.SoftmaxCrossEntropy()\n",
    "\n",
    "# optimizer\n",
    "optimizer = ...\n",
    "\n",
    "# validate once before training\n",
    "train_loss, train_acc = validate(train_loader, model, criterion)\n",
    "val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "\n",
    "# record history for plotting\n",
    "history = ans.utils.MetricsHistory()\n",
    "history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)\n",
    "\n",
    "# optimize\n",
    "for epoch in range(num_epochs):\n",
    "    gc.collect()\n",
    "    \n",
    "    # train loop\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        loss, acc = train_step(inputs, targets, model, criterion, optimizer)\n",
    "        train_loss = 0.99 * train_loss + 0.01 * loss\n",
    "        train_acc = 0.99 * train_acc + 0.01 * acc\n",
    "    \n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "    \n",
    "    history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.best_results('val_acc', 'max'))\n",
    "history.df().plot(secondary_y=['train_acc', 'val_acc']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aec8f5-9015-40fd-802e-270e2a358afb",
   "metadata": {},
   "source": [
    "## Batch normalizace pro 2D vstupy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd03809b",
   "metadata": {},
   "source": [
    "Pokud máte v knihovně `ans` implementovanou normalizaci dávky pro 1D vstupy z minulého cvičení, můžete ji poměrně jednoduše rozšířit pro 2D vstupy.  Tzv. spatial batchonrm, jak se často 2D varianta normalizace dávky označuje v anglické literatuře, *normalizuje přes jednotlivé kanály vstupu*. To znamená, že vektory $\\boldsymbol{\\mu}, \\boldsymbol{\\sigma^2}, \\boldsymbol{\\gamma}, \\boldsymbol{\\beta}, \\boldsymbol{m}, \\boldsymbol{v}^2$ jsou vektory o rozměru $C$. Operaci lze naimplementovat následovně:\n",
    "\n",
    "1. převedení vstupního tensoru $\\boldsymbol{x}$ s rozměry $N \\times C \\times H \\times W$ na 2D matici $(N \\cdot H \\cdot W) \\times C$,\n",
    "2. aplikace 1D batch normalizace\n",
    "3. převedení výstupní matice $(N \\cdot H \\cdot W) \\times C$ zpět do tensoru s rozměry $N \\times C \\times H \\times W$.\n",
    "\n",
    "*Pozor*: převedení tam i zpět nejsou pouhá přetvarování pomocí `reshape`.\n",
    "\n",
    "**Funkce `BatchNorm2d`**\n",
    "\n",
    "Jako funkce by \n",
    "- `BatchNorm2d.forward` měla volat `BatchNorm1d.forward` se správně upravenými vstupy,\n",
    "- `BatchNorm2d.backward` měla volat `BatchNorm1d.backward`  se správně upravenými vstupy.\n",
    "\n",
    "**Vrstva `BatchNorm2d`**\n",
    "\n",
    "Jako vrstva typu `ans.modules.Module` bude mít `BatchNorm2d`\n",
    "- metodu `__init__` shodnou s `BatchNorm1d`, takže ji není nutné implementovat\n",
    "- v metodě `forward` bude volat `ans.functional.BatchNorm2d.apply`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61188af",
   "metadata": {},
   "source": [
    "### TODO: implementujte funkci `ans.functional.BatchNorm2d` a modul `ans.modules.BatchNorm2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da581e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.autograd.gradcheck(\n",
    "    ans.functional.BatchNorm2d.apply,\n",
    "    (\n",
    "        randn_var(3, 4, 5, 8, mean=1., std=2., name='input'),\n",
    "        randn_var(4, name='gamma'),\n",
    "        randn_var(4, name='beta')\n",
    "    ),\n",
    "    params=dict(training=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb6ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convolutional_network.TestBatchNorm2d.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dca7f98",
   "metadata": {},
   "source": [
    "### Konvoluční síť s batch normalizací VGG7BN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c105d8",
   "metadata": {},
   "source": [
    "Batch normalizaci přidáme do modelu VGG7 a výslednou architekturu označíme jako VGG7BN. Zároveň také vypneme u konvolučních vrstev bias, protože jeho efekt by byl stejně ihned následující normalizací opět odečten. Stejným značením jako u VGG7 architektura bude vypadat následovně:\n",
    "\n",
    "`CNR(64), M(2), CNR(128), M(2), CNR(256), M(2), CNR(512), M(2), CNR(512), M(2), LR(512), L(10)`\n",
    "\n",
    "kde:\n",
    "- `N` značí batch normalizaci\n",
    "\n",
    "Architektura je tedy shodná s VGG7, pouze místo bloků konvoluce-relu (`CR`) se opakují bloky konvoluce-normalizace-relu (`CNR`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304c81b0",
   "metadata": {},
   "source": [
    "### TODO: implementujte model `VGG7BN` využívající 2D batch normalizaci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a80bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG7BN(ans.modules.Module):\n",
    "\n",
    "    def __init__(self, num_classes: int, bias: bool = False) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        ########################################\n",
    "        # TODO: implement\n",
    "    \n",
    "        raise NotImplementedError\n",
    "\n",
    "        # ENDTODO\n",
    "        ########################################\n",
    "    \n",
    "    # feel free to add auxiliary methods here\n",
    "    # def my_function(...)\n",
    "    \n",
    "    def forward(self, x: ans.autograd.Variable) -> ans.autograd.Variable:\n",
    "        ########################################\n",
    "        # TODO: implement\n",
    "\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        # ENDTODO\n",
    "        ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f4d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convolutional_network.TestVGG7BN.eval(model_cls=VGG7BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb623ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# reproducibility\n",
    "ans.utils.seed_everything(0)\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = ...\n",
    "batch_size = ...\n",
    "learning_rate = ...\n",
    "momentum = ...\n",
    "weight_decay = ...\n",
    "device = 'cpu'  # set to 'cuda' to run on the GPU\n",
    "\n",
    "# data loaders\n",
    "train_loader = ans.data.DataLoader(\n",
    "    train_dataset_aug,  # use augmented dataset\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "val_loader = ans.data.DataLoader(\n",
    "    val_dataset,\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "# init parameters\n",
    "model = VGG7BN(10)\n",
    "model.to(device=device)\n",
    "\n",
    "# loss function\n",
    "criterion = ans.modules.SoftmaxCrossEntropy()\n",
    "\n",
    "# optimizer\n",
    "optimizer = ...\n",
    "\n",
    "# validate once before training\n",
    "train_loss, train_acc = validate(train_loader, model, criterion)\n",
    "val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "\n",
    "# record history for plotting\n",
    "history = ans.utils.MetricsHistory()\n",
    "history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)\n",
    "\n",
    "# optimize\n",
    "for epoch in range(num_epochs):\n",
    "    gc.collect()\n",
    "    \n",
    "    # train loop\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        loss, acc = train_step(inputs, targets, model, criterion, optimizer)\n",
    "        train_loss = 0.99 * train_loss + 0.01 * loss\n",
    "        train_acc = 0.99 * train_acc + 0.01 * acc\n",
    "    \n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "    \n",
    "    history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143bd46-5535-4deb-957e-2394ddadb8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.best_results('val_acc', 'max'))\n",
    "history.df().plot(secondary_y=['train_acc', 'val_acc']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68081fa-334b-499a-98e9-b06d33f55c3f",
   "metadata": {},
   "source": [
    "## Residuální sítě ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c111cbc",
   "metadata": {},
   "source": [
    "Jako poslední vylepšení můžete zkusit použít residuální bloky, které tvoří základ sítí ResNet. Např. v benchmarku [DAWNBBench](https://dawn.cs.stanford.edu/benchmark/CIFAR10/train.html), kde se kromě jiného hodnotí i rychlost trénování, se na předních pro dataset CIFAR-10 umisťuje varianta ResNet9. Architektura není standardizovaná a publikovaná, byla objevena komunitou a mezi jednotlivými implementacemi se liší. Vyzkoušíme její původní variantu ze série příspěvků o optimalizaci trénování ResNetu na datasetu CIFAR-10 na adrese https://myrtle.ai/learn/how-to-train-your-resnet/.\n",
    "\n",
    "Shodným značením s VGG7 a VGG7BN má model Resnet9 následující architekturu:\n",
    "\n",
    "`CNR(64), CNR(128), M(2), res(CNR(128), CNR(128)), CNR(256), M(2), CNR(512), M(2), res(CNR(512), CNR(512)), M(4), LR(512), L(10)`\n",
    "\n",
    "kde:\n",
    "- `res(convblock)` značí residuální blok formy `z = x + convblock(x)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5189f8",
   "metadata": {},
   "source": [
    "### TODO: implementujte model ResNet9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet9(ans.modules.Module):\n",
    "\n",
    "    def __init__(self, num_classes: int, bias: bool = False) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        ########################################\n",
    "        # TODO: implement\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "        # ENDTODO\n",
    "        ########################################\n",
    "\n",
    "    # feel free to add auxiliary methods here\n",
    "    # def my_function(...)\n",
    "    \n",
    "    def forward(self, x: ans.autograd.Variable) -> ans.autograd.Variable:\n",
    "        ########################################\n",
    "        # TODO: implement\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "        # ENDTODO\n",
    "        ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba4b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convolutional_network.TestResnet9.eval(model_cls=ResNet9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9f2541",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# reproducibility\n",
    "ans.utils.seed_everything(0)\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = ...\n",
    "batch_size = ...\n",
    "learning_rate = ...\n",
    "momentum = ...\n",
    "weight_decay = ...\n",
    "device = 'cpu'  # set to 'cuda' to run on the GPU\n",
    "\n",
    "# data loaders\n",
    "train_loader = ans.data.DataLoader(\n",
    "    train_dataset_aug,  # use augmented dataset\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "val_loader = ans.data.DataLoader(\n",
    "    val_dataset,\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "# init parameters\n",
    "model = ResNet9(10)\n",
    "model.to(device=device)\n",
    "\n",
    "# loss function\n",
    "criterion = ans.modules.SoftmaxCrossEntropy()\n",
    "\n",
    "# optimizer\n",
    "optimizer = ...\n",
    "\n",
    "# validate once before training\n",
    "train_loss, train_acc = validate(train_loader, model, criterion)\n",
    "val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "\n",
    "# record history for plotting\n",
    "history = ans.utils.MetricsHistory()\n",
    "history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)\n",
    "\n",
    "# optimize\n",
    "for epoch in range(num_epochs):\n",
    "    gc.collect()\n",
    "    \n",
    "    # train loop\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        loss, acc = train_step(inputs, targets, model, criterion, optimizer)\n",
    "        train_loss = 0.99 * train_loss + 0.01 * loss\n",
    "        train_acc = 0.99 * train_acc + 0.01 * acc\n",
    "    \n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "    \n",
    "    history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ans22",
   "language": "python",
   "name": "ans22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
